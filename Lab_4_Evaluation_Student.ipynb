{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpA6lL5spzn-"
   },
   "source": [
    "# Recherche d'Information et traitement de données massives\n",
    "\n",
    "# Lab 4 : Evaluation des systèmes de recherche d'information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvuJkzB4pzoB"
   },
   "source": [
    "\n",
    "L'objectif de cette séance est de mettre en oeuvre les différentes approches vues en cours pour évaluer les systèmes de recherche d'information. La première partie du Lab correspond à des exercices d'application disponibles sur EDUNAO (**à faire en dehors de la séance du LAB**) et la deuxième consistera à évaluer et comparer les différents modèles mis en oeuvre dans le LAB 2 et LAB 3, avec différents paramètres, sur la collection TIME.\n",
    "\n",
    "\n",
    "## AVANT-PROPOS\n",
    "\n",
    "Ce Lab clôture le travail pratique de la première partie du cours concernant **les fondements de la Recherche AD Hoc d'information** ainsi que leur application. Plus particulièrement, leur application s'est faite au travers de la création de moteurs de recherche sur la collection `TIME` et aujourd'hui nous clôturerons leur application par leur evaluation, toujours sur la collection `TIME`. Récapitulons les notions vues :\n",
    "+ **Lab 1** : Notions clés de l'étape d'indexation : pré-traitements linguistique sur la collection (**Segmentation, Filtrage, Normalisation**), extraction du **vocabulaire d'indexation** et construction de l'**index inversé**.\n",
    "+ **Lab 2** : Les premiers modèles de recherche de base en RI : **modèle booléen**, **modèle vectoriel** ;\n",
    "+ **Lab 3**: le **modèle de recherche  probabiliste** et, \n",
    "+ **Lab 4** : l'**Evaluation** des systèmes de RI.\n",
    "\n",
    "Ces différents Labs sont donc fortement dépendants. Pour faciliter votre travail, le répertoire concernant le LAB 4 comprend :\n",
    "+ ce fichier qui est donc l'énoncé du LAB.\n",
    "+ un répertoire [Data](./Data) qui contient le répertoire [Time](./Data/TIME) avec l'ensemble des fichiers de la collection.\n",
    "+ un répertoire [Index](./Index) qui contient différents index inversés de la collection `TIME` et plus particulièrement :\n",
    "    + le fichier [index_document](./Index/index_document) qui correspond à l'index de documents de la collection TIME écrit suivant le format décrit dans le LAB 1 et construit avec :\n",
    "        + une segmentation à l'aide du `RegExpTokenizer` de la bibliothèque NLTK ;\n",
    "        + un filtrage à l'aide de la liste des stop-words fournis dans la collection `TIME` ;\n",
    "        + une étape de normalisation par lemmatisation à l'aide du lemmatiseur `WordNetLemmatizer` de la bibliothèque NLTK ;\n",
    "        \n",
    "    + le fichier [index_document.pickle](./Index/index_document.pickle) qui correspond au même index de documents que le précédent mais sauvegardé avec le module [`pickle`](https://www.datacamp.com/community/tutorials/pickle-python-tutorial) de python ;\n",
    "    + le fichier [index_frequence.pickle](./Index/index_frequence.pickle) qui correspond à l'index de fréquence de la collection TIME (avec la même chaîne de traitement que précédemment) ;\n",
    "    + le fichier [index_position.pickle](./Index/index_position.pickle) qui correspond à l'index de position de la collection TIME (avec la même chaîne de traitement que précédemment à l'exception de l'étape de segmentation qui a été faite avec le tokenizer `word_tokenize` de nltk pour respecter l'ordre d'apparition des tokens dans les documents ;\n",
    "+ un répertoire [Utils](./Utils) qui contient les fichiers [Lab1.py](./Utils/Lab1.py) et [Lab2.py](./Utils/Lab2.py) qui contiennent l'ensemble des fonctions utiles des Lab 1 et Lab 2 et pouvant vous servir pour le Lab 4 d'aujourd'hui.\n",
    "    \n",
    "**IL EST DONC IMPORTANT POUR LA SUITE DE BIEN STRUCTURER VOTRE PROJET ET DE BIEN RESPECTER CETTE STRUCTURE. IL FAUDRA DONC BIEN TRAVAILLER DANS UN REPERTOIRE DANS LEQUEL VOUS AUREZ VOTRE FICHIER `.py` (editeur python) OU `.ipynb`(notebook) ET LES REPERTOIRES `DATA`, `INDEX` ET `UTILS` AINSI QUE LES FICHIERS ASSOCIÉS.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## PARTIE 1 : EXERCICES \n",
    "\n",
    "Une série d'exercices est disponible sur EDUNAO et est à travailler en **dehors de la séance**. Elle vous permettra de réviser pour l'examen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMfKSmd2pzoV"
   },
   "source": [
    "## PARTIE 2 : Collection TIME\n",
    "\n",
    "Dans cette partie, nous allons comparer les différents modèles de recherche sur la collection TIME. Nous avons en effet dans la collection un ensemble de requêtes et de jugements de pertinence exhaustifs sur ces requêtes au travers des fichiers fournis. En particulier :\n",
    "+ Le fichier [TIME.QUE](./Data/Time/TIME.QUE) qui contient un ensemble de requêtes exprimées en langage naturel. Chaque requête est identifiée dans le fichier par la chaîne de caractères ` *FIND      ID`\n",
    "+ Le fichier [TIME.REL](./Data/Time/TIME.REL) qui contient les jugements de pertinence exaustifs pour chaque requête. Par exemple la ligne `1  268 288 304 308 323 326 334` doit être interprétée de la manière suivante : les documents pertinents de la collection pour la requête `1` sont les documents `268 288 304 308 323 32` et `334`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Om2rr0XpzoW"
   },
   "source": [
    "### Les différents modèles\n",
    "\n",
    "Nous allons comparer les modèles ci-dessous :\n",
    "+ Le modèle booléen\n",
    "+ Le modèle vectoriel avec différents schémas de pondération :\n",
    "    + La pondération `tf`.\n",
    "    + La pondération `tf-idf`.\n",
    "    + La pondération `tf-idf` normalisée.\n",
    "    + La pondération `tf-idf` logarithmique.\n",
    "    + La pondération `tf-idf` logarithmique normalisée.\n",
    "+ Le modèle probabiliste BIM.\n",
    "+ Le modèle probabiliste OKAPI BM 25.\n",
    "\n",
    "Votre premier travail consiste donc, sur la base des travaux faits dans les LAB 1 et LAB 2, ou des corrections fournies, d'écrire les fonctions permettant d'appliquer ces différents modèles aux requêtes du fichier [TIME.QUE](./Data/Time/TIME.QUE).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZNS-O-E5pzoX"
   },
   "source": [
    "#### Première étape : récupération des index inversés.\n",
    "\n",
    "Dans cette première étape, nous allons récupérer, en les chargeant, les index inversés résultant de l'indexation de la collection `TIME` faite dans le [LAB 1](../Lab1_InvertedIndex/Lab1_Indexation-Student-Correction.ipynb). \n",
    "\n",
    "**1. Chargement de l'index de documents**\n",
    "\n",
    "Vous pouvez pour cela utiliser la fonction `load_inverted_index_pickle(filename)` du fichier `Lab1.py` comme fait dans le code ci-dessous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jEdhkSupzoZ"
   },
   "outputs": [],
   "source": [
    "from Utils.Lab1 import load_inverted_index_pickle\n",
    "\n",
    "# Recupération de l'index de documents\n",
    "index_document = load_inverted_index_pickle(\"./Index/index_document.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GUlAOXnpzod"
   },
   "source": [
    "**2. Chargement de l'index de fréquence**\n",
    "\n",
    "Pour faciliter la suite des traitements cet index sera référencé par une variable nommée `index_frequence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FD9uQ4p5pzof"
   },
   "outputs": [],
   "source": [
    "index_frequence = # A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rV451E1Qpzoj"
   },
   "source": [
    "**3. Chargement de l'index de position**\n",
    "\n",
    "Pour faciliter la suite des traitements cet index sera référencé par une variable nommée `index_position`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kYrEdBpnpzok"
   },
   "outputs": [],
   "source": [
    "index_position = # A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_LA5FkRpzon"
   },
   "source": [
    "#### Deuxième  étape : récupération des requêtes.\n",
    "\n",
    "Votre premier travail consiste à charger le fichier [TIME.QUE](./Data/Time/TIME.QUE) et à parser ce fichier pour récupérer l'ensemble des requêtes que nous utiliserons pour l'évaluation. Comme pour la représentation de la Collection faite dans le LAB 1, on representera cet ensemble de requêtes sous la forme d'un dictionnaire qui a pour clé l'identifiant de la requête (l'`ID` dans la chaîne ` *FIND      ID`) et comme valeur la chaîne de caractères correspondant à la requête en langage naturel.\n",
    "\n",
    "Pour cette étape, il vous est fortement conseillé d'utiliser la même approche que celle développée pour la récupération de la collection dans le Lab 1 et l'utilisation d'expressions régulières.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pr5cJTuKpzoo"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def load_requests(filename):\n",
    "    requests = {}\n",
    "    # A completer\n",
    "    return requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RiJz6yvapzor"
   },
   "source": [
    "Appliquer cette fonction au fichier [TIME.QUE](./Data/Time/TIME.QUE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwzQ-tdzpzos"
   },
   "outputs": [],
   "source": [
    "# A completer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une capture d'écran d'un morceau du résultat :\n",
    "\n",
    "\n",
    "<img src=\"./Figures/requests.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WQo-uHTWpzov"
   },
   "source": [
    "Appliquer à chaque requête la même chaîne de traitements linguistiques que ceux appliqués à la collection (segmentation, filtrage et normalisation). Pensez à utiliser les fonctions du Lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lcld-ltxpzow"
   },
   "outputs": [],
   "source": [
    "from Utils.Lab1 import tokenize_Regexp_corpus,remove_stop_words,load_stop_word,collection_lemmatize\n",
    "\n",
    "tokenized_requests= # A compléter\n",
    "filtered_requests=# A compléter\n",
    "lemmatized_requests=# A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EjvpytcPpzoz"
   },
   "source": [
    "#### Troisième  étape : récupération des jugements de pertinence.\n",
    "\n",
    "Vous allez maintenant récupérer les jugements de pertinence associés à chaque requête en parsant le fichier [TIME.REL](./Data/Time/TIME.REL). Ces jugements de pertinence seront eux aussi stockés sous la forme d'un dictionnaire avec comme **clé** l'`ID`de la requête et comme **valeur** une liste des documents jugés pertinents pour cette requête. Par exemple, la ligne `1  268 288 304 308 323 326 334` du fichier devra donc être représentée comme ceci dans le dictionnaire `{'1': ['268','288', '304', '308', '323', '326', '334' ],...}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3fAo44upzo0"
   },
   "outputs": [],
   "source": [
    "def load_relevance_judgments(filename):\n",
    "    relevance_judgments = {}\n",
    "    # A completer\n",
    "    return relevance_judgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W53DamrXpzo4"
   },
   "source": [
    "Chargez et récupérez les jugements de pertinence de la collection TIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBXuXQu-pzo4"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "relevance_judgments = #a compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une capture d'écran d'un morceau du résultat :\n",
    "\n",
    "\n",
    "<img src=\"./Figures/jugement.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7v5DeyCpzo7"
   },
   "source": [
    "### EVALUATION DE RÉSULTATS DE RECHERCHE NON ORDONNÉS\n",
    "### MODÈLE BOOLÉEN\n",
    "\n",
    "Le modèle booléen est un modèle qui retourne des résultats de recherche non ordonnés. Les métriques que nous pouvons utiliser pour évaluer le système sont donc **le rappel**, **la précision** ou encore la **F-mesure** comme vues en cours et que nous pouvons calculer pour chaque requête ou moyenner sur l'ensemble des requêtes. Le principe pour évaluer le modèle est donc celui expliqué en cours (Cours 4 : évaluation - slide 28).\n",
    "\n",
    "Pour chaque requête :\n",
    "+ Exécuter le modèle sur la collection et récupérer les documents renvoyés par le système.\n",
    "+ Marquer les documents pertinents en comparant avec les jugements de pertinence.\n",
    "+ Calculer le rappel et la précision.\n",
    "\n",
    "On sauvegardera les résultats de l'évaluation sous la forme d'un dictionnaire avec comme clé l'`ID` de la requête et comme valeur un dictionnaire avec une clé par type de mesure et en valeur le résultat de la mesure calculé sur les résultats de la requête. On calculera en particulier pour chaque requête :\n",
    "+ son rappel (clé \"recall\")\n",
    "+ sa précision (clé \"precision\")\n",
    "+ la mesure F_1 (moyenne harmonique simple, c.f. slide 29 du cours 4)\n",
    "+ la mesure F avec un paramètre $\\beta$ de votre choix (c.f. slide 29 du cours 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vy5F0ffVpzo8"
   },
   "source": [
    "A partir des différentes fonctions du LAB 2, écrire le code permettant d'évaluer le modèle booléen sur la collection `TIME`. En particulier il sera utile de :\n",
    "\n",
    "+ Transformer la requête sous sa forme booléenne et la transformer en sa notation polonaise inversée pour pouvoir appliquer les fonctions du LAB 2. On envisagera plusieurs cas :\n",
    "    + Transformation de la requête en requête conjonctive, i.e. on considère que l'ensemble des termes de la requête sont reliés par des `AND`.\n",
    "    + Transformation de la requête en requête disjonctive, i.e. on considère que l'ensemble des termes de la requête sont reliés par des `OR`.\n",
    "+ Vérifier que les termes de la requête sont bien des termes du vocabulaire d'index et les supprimer ou les remplacer par leur mot le plus proche dans le vocabulaire si ce n'est pas le cas. Ici, on se contentera de les supprimer des termes de la requête.\n",
    "+ Supprimer (par simplicité) les mots de type \"U.S\" de la requête car ils ne sont pas supportés par la bibliothèque `tt` utilisée pour implémenter le modèle booléen, de même que les tokens de type nombre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mHXFiI7pzo9"
   },
   "outputs": [],
   "source": [
    "from Utils.Lab2 import *\n",
    "\n",
    "\n",
    "def tranformation_query(query):\n",
    "    # A complter\n",
    "    return boolean_query\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_boolean_model (requests, collection_index, relevance_judgments,BooleanOperator):\n",
    "    evaluation_boolean = {}\n",
    "    # A completer\n",
    "    return evaluation_boolean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "BooleanOperator = {'AND', 'NOT', 'OR'}\n",
    "a = evaluate_boolean_model(lemmatized_requests, index_document, relevance_judgments,BooleanOperator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une capture d'écran d'un morceau du résultat (en considérant le cas d'une requête disjonctive) :\n",
    "\n",
    "\n",
    "<img src=\"./Figures/boolean.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "709FP92Qpzo_"
   },
   "source": [
    "### EVALUATION DE RÉSULTATS ORDONNÉS\n",
    "\n",
    "\n",
    "#### Courbe Rappel-Précision\n",
    "\n",
    "\n",
    "Pour les modèles qui permettent d'ordonner les résultats, nous allons d'abord les comparer à l'aide des courbes rappel-precision.\n",
    "\n",
    "\n",
    "Avant de vous lancer dans cette étape, prenez le temps de relire les slides 31 à 35 du cours 4.\n",
    "\n",
    "Ecrire la fonction `run_model_and_evaluate(query, query_id ,inverted_index, stats, model, relevance_judgments)` qui applique le modèle `model` à la requête et qui calcule les informations rappelées dans le tableau ci-dessous (cf. slide 33).\n",
    "\n",
    "\n",
    "<img src=\"./Figures/recalprecisioncurve.png\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bopdcDCxpzpB"
   },
   "outputs": [],
   "source": [
    "from Utils.Lab2 import *\n",
    "\n",
    "collection_TIME = loadData(\"./Data/Time/TIME.ALL\")\n",
    "pre_processed_collection_TIME = collection_lemmatize(remove_stop_words(tokenize_Regexp_corpus(collection_TIME),\"./Data/Time/TIME.STP\"))\n",
    "stats=get_stats_collection(pre_processed_collection_TIME)\n",
    "\n",
    "\n",
    "\n",
    "def run_model_and_evaluate(query, query_id ,inverted_index, stats, model, relevance_judgments):\n",
    "    # A completer \n",
    "     return result_with_relevance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "query = requests[\"1\"] # requests correspond à l'ensemble des requête récupérer à la \"Deuxième étape : récupération des requêtes.\"\n",
    "print(query)\n",
    "\n",
    "run_model_and_evaluate(query, \"1\", index_frequence,stats, ['frequency','binary'],relevance_judgments)\n",
    "\n",
    "# frequency: weighting_scheme_document (voir Lab2, modèle vectoriel)\n",
    "# binary: weighting_scheme_query (voir Lab2, modèle vectoriel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les questions qui suivent sont optionnelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNS7oMbXpzpE"
   },
   "source": [
    "Ecrire une fonction `draw_recall_precision_curve (query,inverted_index, model, relevance_judgments)` permettant de tracer la courbe rappel-précision pour une requête à partir des résultats obtenus dans la question précédente. Vous pourrez pour cela utiliser la bibliothèque [`matplotlib`](https://matplotlib.org/) et/ou [`seaborn`](https://seaborn.pydata.org/) qu'il vous faudra importer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HG2E7iVpzpF"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def draw_recall_precision_curve (query,inverted_index, model, relevance_judgments):\n",
    "    # A completer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wiXTQWLUpzpI"
   },
   "source": [
    "Comme nous l'avons vu en cours, il est nécessaire de lisser la courbe par interpolation en utilisant la formule $\\forall r_j \\in \\{0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1\\}, P(r_j) = \\max_{r \\geq r_j}{P(r) }$. \n",
    "\n",
    "Ecrire la fonction `interpolate_precision(value,results_precision, results_recall)` permettant de calculer la précision interpolée pour une valeur donnée de $r_j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDoqK5yYpzpJ"
   },
   "outputs": [],
   "source": [
    "def interpolate_precision(value,results_precision, results_recall):\n",
    "    # A completer\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mQMvlRQIpzpL"
   },
   "source": [
    "Appliquer cette fonction pour les 11 valeurs de $r_j : (0;0,1;...;1)$ et conserver ces 11 valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6OQi37c9pzpN"
   },
   "outputs": [],
   "source": [
    "# A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EKk4oT_3pzpQ"
   },
   "source": [
    "Ecrire une fonction `draw_interpolate_recall_precision_curve (query,inverted_index, model, relevance_judgments)` permettant de dessiner la courbe rappel-precision pour une requête donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fm4MMQ0npzpR",
    "outputId": "075db0fb-4087-4c98-b471-15cd208938d7"
   },
   "outputs": [],
   "source": [
    "def draw_interpolate_recall_precision_curve (query,inverted_index, model, relevance_judgments):\n",
    "    # A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pp_AWzNapzpV"
   },
   "source": [
    "Ecrire une fonction `draw_interpolate_recall_precision_curve_test_collection (requests,inverted_index, model, relevance_judgments)` permettant de dessiner la courbe rappel-précision MOYENNE pour l'ensemble des requêtes `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCx3fQ32pzpW",
    "outputId": "446ee628-0db2-48f3-8318-f63228cf8c09"
   },
   "outputs": [],
   "source": [
    "def draw_interpolate_recall_precision_curve_test_collection (requests,inverted_index, model, relevance_judgments):\n",
    "    # A completer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgCbHLKUpzpY"
   },
   "source": [
    "#### Précision moyenne \n",
    "\n",
    "Nous allons maintenant évaluer le résultat d'une requête à l'aide de sa précision moyenne qui est la moyenne des valeurs de précision des documents pertinents par rapport à la requête dans la liste ordonnée des résultats.\n",
    "$$ AveP(q) = \\frac{1}{n_{+}^{q}} \\sum_{k=1}^{N} R_{d_k,q} \\times P@k(q)$$ avec $n_{+}^{q}$ le nombre total de documents pertinents par rapport à $q$ et $P@k(q) = \\frac{1}{k} \\sum_{rg=1}^{k} R_{d_{rg},q}$\n",
    "\n",
    "Ecrire une fonction `mean_precision(query, inverted_index, model, relevance_judgments, k)` permettant de calculer cette métrique pour une requête et une valeur de $k$ donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdWd1sFvpzpZ"
   },
   "outputs": [],
   "source": [
    "def mean_precision(query, inverted_index, model, relevance_judgments, k):\n",
    "    # A completer\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwHdGUenpzpc"
   },
   "source": [
    "### Moyenne des précisions moyennes\n",
    "Ecrire la fonction `mean_average_precision (requests, inverted_index, model, relevance_judgments, k)` calculant la moyenne des précisions moyennes sur un ensemble de requêtes `requests`.\n",
    "\n",
    "$$MAP = \\frac{1}{|Q|}\\sum_{j=1}^{|Q|} AveP(q_j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vsJTfmQpzpc"
   },
   "outputs": [],
   "source": [
    "def mean_average_precision (requests, inverted_index, model, relevance_judgments, k):\n",
    "    # A completer\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APPLICATION ET EVALUATION SUR VOS DIFFERENTS MODÈLES\n",
    "\n",
    "Il s'agit maintenant d'appliquer les métriques d'évaluation précédentes à votre modèle vectoriel avec différents schémas de pondération :\n",
    "  + La pondération `binaire`\n",
    "  + La pondération `tf`.\n",
    "  + La pondération `tf-idf`.\n",
    "  + La pondération `tf-idf` normalisée.\n",
    "  + La pondération `tf-idf` logarithmique.\n",
    "  + La pondération `tf-idf` logarithmique normalisée.\n",
    "  \n",
    "  \n",
    "Nous appliquerons aussi ces métriques sur le modèle probabiliste MIB (modèle d'indépendance binaire) et le modèle probabiliste OKAPI BM 25 vus au Lab 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab_3_Evaluation_Student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
